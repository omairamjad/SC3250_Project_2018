{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: removeGranular\n",
    "Inputs:\n",
    "    df         Dataframe     \n",
    "Outputs:\n",
    "    Dataframe\n",
    "Purpose:\n",
    "Imported data from the Food Balance Sheet of the Food and Agriculture Organization of the United Nations\n",
    "is filtered to exclude data not needed in this analysis. That is, granular details such as specific fruits, \n",
    "veggies, and dairy are removed. As are pre-categories country groupings. \n",
    "Unused columns are also dropped for reasons specified below\n",
    "'''\n",
    "def removeGranular(df):\n",
    "    df = df.loc[(\n",
    "                   (df['Area Code']<1000)  # only keep the countries. All regions are dropped \n",
    "                 & ((df['Item Code']>2900) # only keep category groups.\n",
    "                 & (df['Unit']!='kg'))     # do not keep kg data (using analysis is on calories per person)\n",
    "                 | ((df['Unit']=='g/capita/day') & (df['Item Code']==2901)) # or keep Total Protein data.\n",
    "                )]\n",
    "    df = df.drop([\n",
    "                  'Area Code',   # Area Code is a numeric country code not used elsewhere \n",
    "                  'Flag',        # Flag is quality of the data\n",
    "                  'Year Code'    # Duplicate of Year\n",
    "                 ],axis=1)       # indicator that columnns are to be dropped\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: loadFiles\n",
    "Inputs:\n",
    "    None\n",
    "Outputs:\n",
    "    Tuple     two dataframes. One containing income details, the other food & population details.\n",
    "Purpose:\n",
    "Load in the two source files. \n",
    "Remove unused data to minimize memory usage and improve performance.\n",
    "'''\n",
    "def loadFiles():\n",
    "    foodDataType = { # FAO file structure\n",
    "                    'Area Code': np.int16, \n",
    "                    'Area': np.str, \n",
    "                    'Item Code': np.int16, \n",
    "                    'Item': np.str, \n",
    "                    'Element Code': np.int16, \n",
    "                    'Element': np.str, \n",
    "                    'Year Code': np.int16, \n",
    "                    'Year': np.int16, \n",
    "                    'Unit': np.str, \n",
    "                    'Value': np.float32, \n",
    "                    'Flag': np.str\n",
    "                   }\n",
    "\n",
    "    # import the World Bank income dataset.\n",
    "    # note the first four rows are either blank or have date information and are skipped.\n",
    "    df_GDP = pd.read_csv('Data/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_10181232.csv', skiprows=4)\n",
    "    df_GDP = df_GDP.drop([\n",
    "                        'Country Code',    # three digit country code not used in WorldBank data \n",
    "                        'Indicator Code',  # data reference - consistent for all records.\n",
    "                        '1960'             # 1960 contains very bad data\n",
    "                        ],axis=1)          # indicator that columnns are to be dropped\n",
    "\n",
    "    # import the Food and Agriculture Organization dataset.\n",
    "    df_Load = pd.read_csv('Data/FoodBalanceSheets_E_All_Data_(Normalized).csv', \n",
    "                          dtype=foodDataType,    # file structure \n",
    "                          nrows = 500000,\n",
    "                          encoding='ISO-8859-1')\n",
    "    df_Food = removeGranular(df_Load)\n",
    "        \n",
    "    return df_Food, df_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: UpdateValues\n",
    "Inputs:\n",
    "    df             pandas dataframe. no specific structure\n",
    "    updateColumn   name of the column to be checked\n",
    "    searchFor      string value to search for. This will be dropped from all output unless replaced.\n",
    "    secondColumn   an optional condition that a second column will also be searched\n",
    "    searchSecond   what value to search for in the second column \n",
    "    replaceWith    Add the specified text where the original matching text existed\n",
    "    keepBefore     indicator if text before searched value should be kept\n",
    "    keepAfter      indicator if text after  searched value should be kept\n",
    "Outputs:\n",
    "    dataframe\n",
    "Purpose:\n",
    "Used to get country names consistent between two datasets.\n",
    "'''\n",
    "def UpdateValues(df, updateColumn, searchFor, \n",
    "                 secondColumn='', secondSearch='', \n",
    "                 replaceWith='', keepBefore=True, keepAfter=True):\n",
    "    if secondColumn == '':\n",
    "        valueList = df[updateColumn].loc[(df[updateColumn].str.find(searchFor)>=0)].str.split(searchFor, expand=True)\n",
    "    else:\n",
    "        valueList = df[updateColumn].loc[((df[updateColumn].str.find(searchFor)>=0) & \n",
    "                                         (df[secondColumn] == secondSearch))].str.split(searchFor, expand=True)\n",
    "\n",
    "    valueList = valueList.replace(np.nan, '', regex=True)\n",
    "    if valueList.size >0:\n",
    "        df[updateColumn].update(keepBefore * valueList[0] + replaceWith + keepAfter * valueList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: fixMappings\n",
    "Inputs:\n",
    "    df1            pandas dataframe - FAO\n",
    "    df2            pandas dataframe - World Bank\n",
    "Outputs:\n",
    "    None           original dataframes are modified\n",
    "Purpose:\n",
    "Used to get country names consistent between two datasets. All the necessary rules\n",
    "'''\n",
    "def fixMappings(df1, df2):\n",
    "    # first set fix multple inconsistencies\n",
    "    UpdateValues(df2, 'Country Name', ',', keepAfter=False)\n",
    "    UpdateValues(df2, 'Country Name', 'St.', replaceWith='Saint')\n",
    "    UpdateValues(df1, 'Area', ',', keepBefore=False)\n",
    "    UpdateValues(df1, 'Area', ' \\(', keepAfter=False)\n",
    "    UpdateValues(df1, 'Area', ' People', keepBefore=False)\n",
    "    UpdateValues(df1, 'Area', ' Republic of', keepBefore=False)\n",
    "    UpdateValues(df2, 'Country Name', 'PDR', keepAfter=False)\n",
    "\n",
    "    # below are country specific updates\n",
    "    UpdateValues(df2, 'Country Name', 'Czech Republic', replaceWith='Czechoslovakia') \n",
    "    UpdateValues(df2, 'Country Name', 'Kyrgyz Republic', replaceWith='Kyrgyzstan')   \n",
    "    UpdateValues(df2, 'Country Name', 'United States', replaceWith='United States of America')   \n",
    "    UpdateValues(df1, 'Area', '‚å†', replaceWith='o')\n",
    "    UpdateValues(df1, 'Area', 'Viet Nam', replaceWith='Vietnam')\n",
    "    UpdateValues(df1, 'Element', \" \\(\", keepAfter=False)\n",
    "    UpdateValues(df1, 'Item', \" -\", keepAfter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: updateMissingData\n",
    "Inputs:\n",
    "    df             pandas dataframe - generic\n",
    "Outputs:\n",
    "    None           original dataframes are modified\n",
    "Purpose:\n",
    "Used to linearly estimate missing data (NaN) in a row\n",
    "Where a gap exists in the data - the missing data is straight lined between the two points\n",
    "Where upto three ending points are missing - a linear method is used\n",
    "Gaps at the beginning of the row (or column) are not populated\n",
    "'''\n",
    "def updateMissingData(df, on_axis):\n",
    "    df = df.interpolate(method='linear', axis=on_axis, limit=10, limit_area='inside')\n",
    "    df = df.interpolate(method='linear', axis=on_axis, limit=3, limit_area='outside')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    food, incomes = loadFiles()\n",
    "    fixMappings(food, incomes)\n",
    "    \n",
    "    # because each row contains headers we only pass the data points.\n",
    "    incomes[incomes.columns[4:]] = updateMissingData(incomes[incomes.columns[4:]],1)\n",
    "    \n",
    "    # undo the pivot table so years are in a single column. This will make graphs easier.\n",
    "    incomes = pd.melt(incomes, id_vars=['Country Name', 'Indicator Name'], var_name='Year', value_name='Value')\n",
    "\n",
    "\n",
    "    food.to_csv('food.csv')\n",
    "    incomes.to_csv('incomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__main__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
