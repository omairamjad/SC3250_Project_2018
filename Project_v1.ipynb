{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: removeGranular\n",
    "Inputs:\n",
    "    df         Dataframe     \n",
    "Outputs:\n",
    "    Dataframe\n",
    "Purpose:\n",
    "Imported data from the Food Balance Sheet of the Food and Agriculture Organization of the United Nations\n",
    "is filtered to exclude data not needed in this analysis. That is, granular details such as specific fruits, \n",
    "veggies, and dairy are removed. As are pre-categories country groupings. \n",
    "Unused columns are also dropped for reasons specified below\n",
    "'''\n",
    "def removeGranular(df):\n",
    "    df = df.loc[(\n",
    "                   (df['Area Code']<1000)  # only keep the countries. All regions are dropped \n",
    "                 & ((df['Item Code']>2900) # only keep category groups.\n",
    "                 & (df['Unit']!='kg'))     # do not keep kg data (using analysis is on calories per person)\n",
    "                 | ((df['Unit']=='g/capita/day') & (df['Item Code']==2901)) # or keep Total Protein data.\n",
    "                )]\n",
    "    df = df.drop([\n",
    "                  'Area Code',   # Area Code is a numeric country code not used elsewhere \n",
    "                  'Flag',        # Flag is quality of the data\n",
    "                  'Year Code'    # Duplicate of Year\n",
    "                 ],axis=1)       # indicator that columnns are to be dropped\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: loadFiles\n",
    "Inputs:\n",
    "    None\n",
    "Outputs:\n",
    "    Tuple     two dataframes. One containing income details, the other food & population details.\n",
    "Purpose:\n",
    "Load in the two source files. \n",
    "Remove unused data to minimize memory usage and improve performance.\n",
    "'''\n",
    "def loadFiles():\n",
    "    foodDataType = { # FAO file structure\n",
    "                    'Area Code': np.int16,    # index representing the country or region\n",
    "                    'Area': np.str,           # string of the country\n",
    "                    'Item Code': np.int16,    # index of the item. Groups > 2900\n",
    "                    'Item': np.str,           # item or group of food\n",
    "                    'Element Code': np.int16, # index of element\n",
    "                    'Element': np.str,        # what is being measured\n",
    "                    'Year Code': np.int16,    # year\n",
    "                    'Year': np.int16,         # year\n",
    "                    'Unit': np.str,           # unit scale - can be used as a label\n",
    "                    'Value': np.float32,      # \n",
    "                    'Flag': np.str            # notes on accuracy\n",
    "                   }\n",
    "\n",
    "    # import the World Bank income dataset.\n",
    "    # note the first four rows are either blank or have date information and are skipped.\n",
    "    df_GDP = pd.read_csv('Data/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_10181232.csv', skiprows=4)\n",
    "    df_GDP = df_GDP.drop([\n",
    "                        'Indicator Code',  # data reference - consistent for all records.\n",
    "                        'Indicator Name',    # three digit country code used in Region Table \n",
    "                        '1960'             # 1960 contains very bad data\n",
    "                        ],axis=1)          # indicator that columnns are to be dropped\n",
    "    df_GDP.rename({'Value':'Income'})\n",
    "\n",
    "    # import the Food and Agriculture Organization dataset.\n",
    "    df_Load = pd.read_csv('Data/FoodBalanceSheets_E_All_Data_(Normalized).csv', \n",
    "                          dtype=foodDataType,    # file structure \n",
    "                          nrows = 3000,\n",
    "                          encoding='ISO-8859-1') # file format\n",
    "    df_Food = removeGranular(df_Load)\n",
    "    \n",
    "    df_Regions = pd.read_csv('https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv')\n",
    "        \n",
    "    return df_Food, df_GDP, df_Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: UpdateValues\n",
    "Inputs:\n",
    "    df             pandas dataframe. no specific structure\n",
    "    updateColumn   name of the column to be checked\n",
    "    searchFor      string value to search for. This will be dropped from all output unless replaced.\n",
    "    secondColumn   an optional condition that a second column will also be searched\n",
    "    searchSecond   what value to search for in the second column \n",
    "    replaceWith    Add the specified text where the original matching text existed\n",
    "    keepBefore     indicator if text before searched value should be kept\n",
    "    keepAfter      indicator if text after  searched value should be kept\n",
    "Outputs:\n",
    "    dataframe\n",
    "Purpose:\n",
    "Used to get country names consistent between two datasets.\n",
    "'''\n",
    "def UpdateValues(df, updateColumn, searchFor, \n",
    "                 secondColumn='', secondSearch='', \n",
    "                 replaceWith='', keepBefore=True, keepAfter=True):\n",
    "    if secondColumn == '':                                          # If search only one parameter\n",
    "        valueList = df[updateColumn].loc[(                          # create new dataset from updateColumn\n",
    "            df[updateColumn].str.find(searchFor)>=0)].str.split(    # locate rows where characters (searchFor) exists\n",
    "            searchFor, expand=True)                                 # split into a columns before and after search string\n",
    "\n",
    "    else:                                                           # If search two parameters\n",
    "        valueList = df[updateColumn].loc[((                         # create new dataset from updateColumn\n",
    "            df[updateColumn].str.find(searchFor)>=0)                # locate rows where characters (searchFor) exists\n",
    "            & (df[secondColumn] == secondSearch))].str.split(       # and secondColumn is EQUAL to secondSearch\n",
    "            searchFor, expand=True)                                 # split into a columns before and after search string\n",
    "\n",
    "    valueList = valueList.replace(np.nan, '', regex=True)           # if any components are blank change to null string\n",
    "    if valueList.size >0:                                           # if more than one element found then update\n",
    "        df[updateColumn].update(\n",
    "            keepBefore * valueList[0]      # KeepBefore (True/False) * (characters before search term) \n",
    "            + replaceWith                  # search text removed. add this instead.\n",
    "            + keepAfter * valueList[1]     # KeepAfter  (True/False) * (characters after search term)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: fixMappings\n",
    "Inputs:\n",
    "    df1            pandas dataframe - FAO\n",
    "    df2            pandas dataframe - World Bank\n",
    "Outputs:\n",
    "    None           original dataframes are modified\n",
    "Purpose:\n",
    "Used to get country names consistent between two datasets. All the necessary rules\n",
    "'''\n",
    "def fixMappings(df1, df2):\n",
    "    # first set fix multple inconsistencies\n",
    "    UpdateValues(df2, 'Country Name', ',', keepAfter=False)\n",
    "    UpdateValues(df2, 'Country Name', 'St.', replaceWith='Saint')\n",
    "    UpdateValues(df1, 'Area', ',', keepBefore=False)\n",
    "    UpdateValues(df1, 'Area', ' \\(', keepAfter=False)               # fix Not working\n",
    "    UpdateValues(df1, 'Area', ' People', keepBefore=False)\n",
    "    UpdateValues(df1, 'Area', ' Republic of', keepBefore=False)\n",
    "    UpdateValues(df2, 'Country Name', 'PDR', keepAfter=False)\n",
    "\n",
    "    # below are country specific updates\n",
    "    UpdateValues(df2, 'Country Name', 'Czech Republic', replaceWith='Czechoslovakia') \n",
    "    UpdateValues(df2, 'Country Name', 'Kyrgyz Republic', replaceWith='Kyrgyzstan')   \n",
    "    UpdateValues(df2, 'Country Name', 'United States', replaceWith='United States of America')   \n",
    "    UpdateValues(df1, 'Area', 'd\\'', replaceWith='Cote d\\'', keepBefore=False)\n",
    "    UpdateValues(df1, 'Area', 'Viet Nam', replaceWith='Vietnam')\n",
    "    UpdateValues(df1, 'Element', \" \\(\", keepAfter=False)            # fix Not working\n",
    "    UpdateValues(df1, 'Item', \" -\", keepAfter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Procedure: updateMissingData\n",
    "Inputs:\n",
    "    df             pandas dataframe - generic\n",
    "Outputs:\n",
    "    None           original dataframes are modified\n",
    "Purpose:\n",
    "Used to linearly estimate missing data (NaN) in a row\n",
    "Where a gap exists in the data - the missing data is straight lined between the two points\n",
    "Where upto three ending points are missing - a linear method is used\n",
    "Gaps at the beginning of the row (or column) are not populated\n",
    "\n",
    "*************************************\n",
    "NOTE - We should set a flag to show the data is estimated. Then if desired we can put colours on the graph.\n",
    "     - Also useful for 'confidence' in the particular relationship. Very nice for the documentation.\n",
    "*************************************\n",
    "'''\n",
    "def updateMissingData(df, on_axis):\n",
    "    df = df.interpolate(method='linear', axis=on_axis, limit=10, limit_area='inside')   # fix - change to poly\n",
    "    df = df.interpolate(method='linear', axis=on_axis, limit=3, limit_area='outside')   # fix - impute\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroupRegions (df):\n",
    "    df['region'].update(df['sub-region'].loc[(\n",
    "            df['region'].str.find('Americas')>=0)])\n",
    "\n",
    "    df['region'].update(df['sub-region'].loc[(\n",
    "            df['region'].str.find('Asia')>=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    food, incomes, regions = loadFiles()\n",
    "    fixMappings(food, incomes)\n",
    "    regroupRegions (regions)\n",
    "            \n",
    "    # because each row contains headers we only pass the data points.\n",
    "    incomes[incomes.columns[4:]] = updateMissingData(incomes[incomes.columns[4:]],1)\n",
    "    \n",
    "    # undo the pivot table so years are in a single column. This will make graphs easier.\n",
    "    incomes = pd.melt(incomes, id_vars=['Country Name', 'Country Code'], var_name='Year', value_name='Income')\n",
    "    incomes['Year'] = pd.to_numeric(incomes['Year'], errors='coerce',downcast= 'integer')\n",
    "    \n",
    "    # combine regions and income table = match on 3-digit country code\n",
    "    df_working = pd.merge (left = incomes, \n",
    "                           right = regions[['alpha-3','region']], \n",
    "                           how = 'inner', \n",
    "                           left_on = 'Country Code',\n",
    "                           right_on = 'alpha-3')\n",
    "\n",
    "    df_working = pd.merge (left = df_working,\n",
    "                           right = food,\n",
    "                           how = 'inner',\n",
    "                           left_on = ['Country Name','Year'],\n",
    "                           right_on = ['Area','Year'])\n",
    "    df_working.to_csv('working.csv')\n",
    "    #food.to_csv('food.csv')\n",
    "    #incomes.to_csv('incomes.csv')\n",
    "    #return pandas_profiling.ProfileReport(food)\n",
    "    \n",
    "    ### combine into a single dataset\n",
    "    ### df.set_index(['year', 'country', 'field'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1113 entries, 53 to 1218\n",
      "Data columns (total 8 columns):\n",
      "Area            1113 non-null object\n",
      "Item Code       1113 non-null int16\n",
      "Item            1113 non-null object\n",
      "Element Code    1113 non-null int16\n",
      "Element         1113 non-null object\n",
      "Year            1113 non-null int16\n",
      "Unit            1113 non-null object\n",
      "Value           1113 non-null float32\n",
      "dtypes: float32(1), int16(3), object(4)\n",
      "memory usage: 54.3+ KB\n",
      "None\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "% time __main__() #.to_file(\"Data_Profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*************************************\\nWhen building graphs put in loops and a delay of a few seconds between each update. This might allow movement in the output.\\nThis way we can build up (keep original if showing 1-5 areas), or hide previous if showing multiple (video)\\nIf doing only a few areas - consider moving labels instead of a legend.\\n\\nhttps://scipy-cookbook.readthedocs.io/items/Matplotlib_Animations.html\\n\\nCan we estimatate and plot the confidence interval?\\n*************************************'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''*************************************\n",
    "When building graphs put in loops and a delay of a few seconds between each update. This might allow movement in the output.\n",
    "This way we can build up (keep original if showing 1-5 areas), or hide previous if showing multiple (video)\n",
    "If doing only a few areas - consider moving labels instead of a legend.\n",
    "\n",
    "https://scipy-cookbook.readthedocs.io/items/Matplotlib_Animations.html\n",
    "\n",
    "Can we estimatate and plot the confidence interval?\n",
    "*************************************'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
